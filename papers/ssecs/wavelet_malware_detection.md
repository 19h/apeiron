# Wavelet Decomposition of Software Entropy Reveals Symptoms of Malicious Code

**Michael Wojnowicz\*, Glenn Chisholm, Matt Wolff, Xuan Zhao**

Cylance, Inc., 18201 Von Karman Ave., Irvine, CA 92612, United States

*Journal of Innovation in Digital Ecosystems 3 (2016) 130–140*

---

## Highlights

- Development of new features for machine learning
- Application of wavelet transforms to software entropy
- Discovery of suspicious patterns of entropic change
- Automatic classification of parasitic malware

---

## Abstract

Sophisticated malware authors can sneak hidden malicious contents into portable executable files, and this contents can be hard to detect, especially if encrypted or compressed. However, when an executable file switches between contents regimes (e.g., native, encrypted, compressed, text, and padding), there are corresponding shifts in the file's representation as an entropy signal. In this paper, we develop a method for automatically quantifying the extent to which patterned variations in a file's entropy signal make it "suspicious".

In Experiment 1, we use wavelet transforms to define a Suspiciously Structured Entropic Change Score (SSECS), a scalar feature that quantifies the suspiciousness of a file based on its distribution of entropic energy across multiple levels of spatial resolution. Based on this single feature, it was possible to raise predictive accuracy on a malware detection task from 50.0% to 68.7%, even though the single feature was applied to a heterogeneous corpus of malware discovered "in the wild".

In Experiment 2, we describe how wavelet-based decompositions of software entropy can be applied to a parasitic malware detection task involving large numbers of samples and features. By extracting only string and entropy features (with wavelet decompositions) from software samples, we are able to obtain almost 99% detection of parasitic malware with fewer than 1% false positives on good files. Moreover, the addition of wavelet-based features uniformly improved detection performance across plausible false positive rates, both in a strings-only model (e.g., from 80.90% to 82.97%) and a strings-plus-entropy model (e.g. from 92.10% to 94.74%, and from 98.63% to 98.90%). Overall, wavelet decomposition of software entropy can be useful for machine learning models for detecting malware based on extracting millions of features from executable files.

**Keywords:** Wavelet decomposition, Structural entropy, Malware detection, Parasitic malware, Machine learning

---

## 1. Introduction

### 1.1. The Entropy of Malicious Software

A fundamental goal in the information security industry is malware detection. In this paper, we focus our malware detection efforts on the fact that malicious files (e.g. parasitics, or exploits with injected shellcode) commonly contain encrypted or compressed ("packed") segments which conceal malicious contents [1]. Thus, the information security industry has been interested in developing methodologies which can automatically detect the presence of encrypted or compressed segments hidden within portable executable files. To this end, entropy analysis has been used, because files with high entropy are relatively likely to have encrypted or compressed sections inside them [2].

In general, the entropy of a random variable reflects the amount of uncertainty (or lack of knowledge) about that variable. In the context of software analysis, zero entropy would mean that the same character was repeated over and over (as might occur in a "padded" chunk of code), and maximum entropy would mean that a chunk consisted of entirely distinct values. Thus, chunks of code that have been compressed or encrypted tend to have higher entropy than native code. For instance, in the software corpus studied by [2], plain text had an average entropy of 4.34, native executables had an average entropy of 5.09, packed executables had an average entropy of 6.80, and encrypted executables had an average entropy of 7.17.

### 1.2. Suspiciously Structured Entropy

Based on the reasoning above, previous research has used high mean entropy as an indicator of encryption or compression. However, malicious contents, when concealed in a sophisticated manner, may not be detectable through simple entropy statistics, such as mean file entropy. Malware writers sometimes try to conceal hidden encrypted or compressed contents that they introduce in creating files such as parasitic malware; for instance, they may add additional padding (zero entropy chunks), so that the file passes through high entropy filters. However, files with concealed encrypted or compressed segments tend to vacillate markedly between native contents, encrypted and compressed segments, and padding, with each segment having distinct and characteristic expected entropy levels.

Thus, the field of cybersecurity has started to pay attention to files with highly structured entropy [3,4], that is, files whose contents flips between various distinguishing levels of entropy through the file.

In order to automatically identify the degree of entropic structure within a piece of software, we represent each portable executable file as an "entropy stream." The entropy stream describes the amount of entropy over a small snippet of code in a certain location of the file. The "amount" of entropic structure can then be quantified, such that we can differentiate, for example, between a low-structured signal with a single local mean and variation around that mean, versus a highly-structured signal whose local mean changes many times over the course of the file.

In this paper,[^1] we define **suspiciously structured entropy** as a particular pattern of entropic structure which matches those of malicious files. To quantify the suspiciousness of the structured entropy within a piece of software, we develop the notion of a "Suspiciously Structured Entropic Change Score" (SSECS). We first describe how to calculate SSECS as a single predictive feature, and analyze its performance in malware detection. We then generalize this feature to large-scale malware detection tasks. The derivation of the SSECS feature depends upon the notion of a wavelet transform, which we now briefly review.

[^1]: This paper is a development of earlier research originally published in conference proceedings [5]. For an even more comprehensive viewpoint, see [6].

### 1.3. Brief Overview of Wavelets

The Wavelet Transform is the primary mathematical operator underlying our quantification of structurally suspicious entropy. The Wavelet Transform extracts the amount of "detail" exhibited within a signal at various locations over various levels of resolution [7]. In essence, it transforms a one-dimensional function of "location" (in our case, file location) into a two-dimensional function of "location" and "scale." By using the output of the wavelet transform (the so-called "wavelet coefficients"), it is possible to obtain a series of coarse-to-fine approximations of an original function. These successive approximations allow us to determine the multi-scale structure of the entropy signal, in particular the "energy" available at different levels of resolution.

For this paper, we apply **Haar Wavelets**, which is a particularly simple family of wavelets whose members are piecewise constant. The Haar Wavelet Transform projects the original entropy signal onto a collection of piecewise constant functions which oscillates as a square wave over bounded support (i.e., these functions assume non-zero values only on certain bounded intervals). Since these piecewise constant functions have supports which vary in their scale (width) and location, the resulting projections describe the "detail" within the signal at various locations and resolutions.

More specifically, the Haar Wavelet Transform is based upon the so called "mother function", ψ(t), defined by:

$$
\psi(t) = \begin{cases}
1, & t \in [0, 1/2) \\
-1, & t \in [1/2, 1) \\
0, & \text{otherwise}
\end{cases}
$$

a very simple step function. Given the Haar mother function ψ(t), a collection of dyadically scaled and translated wavelet functions ψ_{j,k}(t) are formed by:

$$
\psi_{j,k}(t) = 2^{j/2}\psi(2^j t - k) \tag{1}
$$

where the integers j, k are scaling parameters. The dilation parameter j indexes the level of detail or spatial resolution, and the translation parameter k selects a certain location within the signal to be analyzed. Note that as the scaling parameter j increases, the function ψ_{j,k} applies to (is non-zero over) successively finer intervals of the signal.

> **Figure 1** – Examples of Haar wavelet functions. Haar wavelet functions over the unit interval are shown. Each colored square wave represents (the non-zero part of) a different wavelet function. The Haar wavelet functions are defined in Eq. (1). In particular, wavelet functions for resolution levels j = 0, 1, 2 and locations k = 0, . . . , j are plotted. These wavelet functions are used as filters to pick up the magnitude of entropic change in a piece of software at different levels of resolution and in different file locations.

Given a signal x(t) where t = 1, . . . , T, we first rescale the signal so that the first observation occurs at time t = 0 and the final observation occurs at time t = 1. Then, the so-called "mother wavelet coefficient" at scale j and location k is given by the inner product of the signal with the wavelet. Since we are dealing with discrete signals, the inner product takes the form:

$$
d_{j,k} = \langle x, \psi_{j,k} \rangle = \sum_{t=1}^{T} x(t)\psi_{j,k}(t)
$$

One interpretation of this coefficient is that it gives the (scaled) difference between local averages of the signal across neighboring chunks or bins. The size of the neighboring chunks is determined by the scaling parameter j.

The family of mother wavelet coefficients, {d_{j,k}}, enable a "Multi-Resolution Analysis" (MRA) of the signal x(t). In particular, the signal x(t) can be decomposed into a series of approximations x_j(t), whereby each successive approximation x_{j+1}(t) is a more detailed refinement of the previous approximation, x_j(t). The functional approximations are obtained through the wavelet coefficients by the formula:

$$
x_{j+1}(t) = x_j(t) + \sum_{k=0}^{2^{j}-1} d_{j,k}\psi_{j,k}(t) \tag{2}
$$

where x_0(t), the coarsest-level functional approximation, is the mean of the full signal. Thus, the collection of mother wavelet coefficients {d_{j,k}} store the "details" that allow one to move from a coarser approximation to a finer approximation.

> **Figure 2** – Wavelet-based functional approximations to a software's entropy signal at different levels of resolution. The entropy signal from a single Portable Executable (PE) file is projected onto Haar father wavelet space at different levels of resolution (j ∈ {2, 5, 8} from Eq. (2)). In general, each successive functional approximation adds the incremental detail provided at that level of spatial resolution, compared to the next-most-coarse level of spatial resolution, and does so across various spatial locations.

Using the wavelet transform, it is possible to "summarize" the overall amount of detail in a signal at various levels of resolution. The total amount of detail at a particular (jth) level of resolution is known as the **energy** at that level of resolution:

$$
E_j = \sum_{k=1}^{2^{j}-1} (d_{jk})^2 \tag{3}
$$

The distribution of energy across various levels of resolution is known as an **energy spectrum**. Note that the energy at resolution level j is just the squared Euclidean norm of the vector of mother wavelet coefficients from resolution level j. After this step, we have reduced the original signal of size T = 2^J (and resultant wavelet vector of size T − 1) to a vector of J elements, where each element represents the amount of "energy" at a single level of resolution.

### 1.4. Wavelet-Based Classifiers

The energy spectra of signals have been very useful features for classifiers such as neural networks. In fact, this combined strategy, whereby the coefficients from a discrete wavelet transform are used as node activations in a neural network, is referred to as a wavelet neural network (WNN) (see e.g. [8, 9]). Using WNN's, researchers have been able to automatically classify lung sounds into categories (crackles, wheezes, striders, squawks, etc.) [10], to automatically determine whether brain EEG scans originated from healthy patients, patients with epilepsy, or patients who were in the middle of having a seizure [11], or to automatically determine whether EMG signals collected from the bicep originated from patients who were healthy, suffering from myopathy, or suffering from neurogenic disease [12].

We refer to the overall strategy of using wavelet coefficients as features in a classifier as a **Wavelet-Based Classifier** strategy. We prefer this term over WNN, which, although well-established in the literature, is specific to neural network classifiers. Indeed, in this paper, we choose logistic regression (both standard and regularized) rather than a neural network to model our data, because the logistic regression model provides an atomic analysis of the relationship between the wavelet-based features and classification categories.

### 1.5. Suspiciously Structured Entropic Change Score (SSECS)

The initial fundamental problem with applying wavelet-based classifiers to malware analysis is that executable files out "in the wild" have different lengths. This contrasts with controlled observational situations, e.g. those described above, which produce signal samples of a fixed length which is constant across the data set. In controlled observational situations, all samples will produce the same number of features, J, and variation across these set of J features can be immediately associated with a classification variable in a straightforward manner, for example by setting the input layer of the neural network to have J activation notes.

However, in uncontrolled observational contexts, signal lengths can differ wildly from sample to sample. Imagine, for instance, comparing signal A of length 32 (so J = 5, and if E_{f,j} represents the energy at resolution level j = 1, . . . , J for portable executable file f, we would have E_{a,1}, . . . , E_{a,5}) with signal B of length 256 (so J = 8, and we have E_{b,1}, . . . , E_{b,8}). How should we compare these two files?

Our solution to this problem, for smaller data sets,[^2] is to transform each file's J-dimensional energy spectrum into a single scalar feature, a 1-dimensional "Suspiciously Structured Entropic Change Score" (SSECS). The computation of SSECS is a two-step process: first, we compute the wavelet-based energy spectrum of a file's entropy signal, and second, we compute the file's malware propensity score from that energy spectrum. In our case, we fit a logistic regression model to the binary classification response (malware or not) which uses these wavelet energy features as predictor variables. We fit J separate regression models, one for each file size grouping. Given the Energy Spectrum {E_{f,j}}, which is the set of wavelet energies for each resolution level j = 1, . . . , J of portable executable file f, the logistic regression model estimates P_f, the predicted probability that file f is malware, by the formula:

$$
P_f = \frac{1}{1 + \exp[-(\beta_0 + E_f \cdot \beta^{(J)})]}
$$

where E_f is a J-dimensional vector representing the observed wavelet energy spectra of file f, where β^{(J)} is a vector of model parameters, known as the "logistic regression coefficients," which govern the model weights on the observed energy spectra for all files with J features in the energy spectrum, and where β_0 is a model intercept. This number, P_f is what we refer to as the **SSECS**.

[^2]: A second solution, for larger datasets, is described in Experiment 2.

---

## 2. Experiment 1: Analyzing and Evaluating the Predictive Performance of a Single Wavelet-Based Feature

In Experiment 1, we attempt to assess the predictive value of SSECS as a single feature describing potentially suspicious variation in software entropy. In particular, as discussed in Section 2.2, the wavelet-based feature is constructed in an attempt to describe the "suspiciousness" of a piece of software's entropy signal when that entropy signal is re-represented, through a wavelet transform, in terms of entropic change distributed across different levels of spatial resolution.

### 2.1. Data

Data are a set of n = 39,968 portable executable files from a Cylance repository. 19,988 (50.01%) of these files were known to be malicious, and the remaining files were benign. These files were collected "from the wild", and thus highly heterogeneous. For example, the "malware" category contains different types of malicious software (e.g. viruses, Trojan horses, spyware, backdoors, bots, and ransomware—but not adware.)

### 2.2. Method

#### 2.2.1. Constructing the Entropy Stream

To compute the entropy of an executable file, the original file, represented in hexadecimal (00h-FFh), is split into non-overlapping chunks of fixed length, typically 256 bytes. For each chunk of code, the entropy is then computed using the formula below:

$$
H(c) = -\sum_{i=1}^{m} p_i(c) \log_2 p_i(c) \tag{4}
$$

where c represents a particular chunk of code, m represents the number of possible characters (here, m = 256), and p_i is the probability (observed frequency) of each character in the given chunk of code. The entropy for any given chunk then ranges from a minimum of 0 to a maximum of 8.

#### 2.2.2. Computing the Suspiciously Structured Entropic Change Score (SSECS)

The procedure for computing the suspiciously structured entropic change score (SSECS) is as follows:

**(1) Partition data set by size:** Group sampled files into j = {1, . . . , J} groups, where j = ⌊log₂T⌋ and T is the length of the file's entropy stream.

**(2) Iterate:** For all files which fall into the jth length group:

**(2a) Compute Haar Discrete Wavelet Coefficients:** The discrete wavelet transform takes as input a discrete series of size T = 2^J observations. Because the transform requires the series to have a dyadic length, if the number of observations in the executable file's entropy stream is not an integer power of 2, we right-truncate the series at value 2^{⌊log₂T⌋}. The so-called "mother" wavelet coefficients, d_{jk}, describe the "detail" at successively fine-grained resolutions.

In particular, the mother wavelet coefficients are indexed such that j ∈ {1, . . . , J} represents the resolution level, ordered from coarse-grained to fine-grained, and k ∈ {1, . . . , K = 2^{j−1}} represents the particular location (or bin) of the entropy signal at that resolution level. At each resolution level j, the signal is divided into N_j = 2^{j−1} non-overlapping, adjacent bins such that each bin includes B_j = 2^{J−j} observations. Note that the number of bins, K, increases as j increases to finer resolutions. The mother wavelet coefficient at index (k, j) is then given by:

$$
d_{kj} = \frac{1}{s_j}\left(\sum_{i=(2k-1)B_j+1}^{2kB_j} y_i - \sum_{i=(2k-2)B_j+1}^{(2k-1)B_j} y_i\right) \tag{5}
$$

where the scaling factor is s_j = (√2)^{J−j+1} and is necessary for the wavelet transform to preserve the size (norm) of the signal. There are T − 1 mother wavelet coefficients.

**(2b) Compute Wavelet Energy Spectrum:** The wavelet energy spectrum summarizes the "detail" or "variation" available at various resolution levels. The energy spectrum is computed as a function of the mother wavelet coefficients, d_{jk}. In particular, the "energy", E_j, of the entropy stream at the jth resolution level is defined by Eq. (3). Given a particular executable file's entropy stream, we refer to its distribution of energy over different resolutions as the file's "energy spectrum".

**(2c) Compute Wavelet Energy Suspiciousness:** Now we use the wavelet energy spectrum to determine the "propensity" of each file to be malware (i.e., its suspiciousness). Computing this propensity requires training. We use 5-fold validation.

**(2c1) Partition The Current Sample Of Files:** Split the entire set of F_J files which are of the appropriate size into 5 mutually exclusive subsets F¹_J, . . . , F⁵_J, each of which represents exactly 20% of the entire sample.

**(2c2) Iterate:** For each subset Fⁱ_J, where i ∈ {1, . . . , 5}:

**(2c2a) Fit a logistic regression:** Fit a logistic regression model on the other four subsets {Fᵏ_J : k ≠ i}, where the model fits the class variable (malware or not) as a function of the wavelet energy spectrum. The logistic regression model will produce a set of beta coefficients to weigh the strength of each resolution energy on the file's probability of being malware.

**(2c2b) Calculate malware propensity:** Use the logistic regression model above to then make a prediction about files in subset Fⁱ_J. In particular, use the model learned in step 2c2a to calculate the predicted probability that each file in set Fⁱ_J is malware, given its wavelet energy spectrum. This malware propensity (i.e., predicted malware probability) lies within the interval [0, 1], and is what we call the **Suspiciously Structured Entropic Change Score (SSECS)**.

### 2.3. Results

#### 2.3.1. Suspicious Patterns of Entropic Change in a Single File Size Group

How does the model transform these wavelet energy spectra into predictions about whether the file is malware (that is, into a Suspiciously Structured Entropic Change Score)? To illustrate, we consider the subset of n = 1599 files in our corpus belonging to file size group J = 5. Because these files can be analyzed at J = 5 different spatial resolutions, we extract 5 features from each file, with each feature representing the energy at one level of spatial resolution in the file's entropy stream.

For illustrative purposes, we begin by analyzing the wavelet energy spectrum for two files from this size category, as they embody more general trends in the energy patterns of malicious versus clean files.

> **Figure 3** – Wavelet-based functional approximations, and the corresponding wavelet energy spectrum, for the entropy signals of two representative portable executable files from one file size group. The left column depicts the entropy signal from File A (legitimate software), whereas the right column depicts the entropy signal from File B (malware). Reading columns from top to bottom shows successively detailed functional approximations. The title above each subplot shows the wavelet energy at a particular spatial resolution level.

Based on this entropic energy spectrum decomposition (or distribution of energy across various levels of spatial resolution), the model believes that File A is legitimate software, whereas File B is malware. Investigating this conclusion, we see that these two files have radically different wavelet energy distributions across the 5 levels of spatial resolution. The legitimate software (File A) has its "entropic energy" mostly concentrated at finer levels of resolution, whereas the piece of malware (File B) has its "entropic energy" mostly concentrated at coarser levels of resolution. For the clean file, the energy in the entropy stream is concentrated at the resolution levels j = 4 and j = 5 (where the energy is 34.5 and 23.84 squared bits, respectively). For the dirty file, the energy in the entropy signal is concentrated at coarser levels of analysis, peaking especially strongly at level j = 2 (where the energy is 139.99 squared bits).

**Table 1** – Investigating the relationship between the entropic wavelet energy spectrum and maliciousness for files in one size group.

| Resolution Level | # Bins | Bin Size | File A Energy | File B Energy | Value of β_j | P-value | Malware Sensitivity |
|------------------|--------|----------|---------------|---------------|--------------|---------|---------------------|
| 1 | 2 | 16 | −0.39 (4.35) | −0.01 (14.44) | 0.448 (0.017) | \*\*\*\*\* | +56.5% (+1.7%) |
| 2 | 4 | 8 | −0.79 (0.80) | 6.27 (139.99) | 0.174 (0.008) | \* | +19.0% (+0.89%) |
| 3 | 8 | 4 | −0.48 (5.29) | 2.18 (53.83) | 0.847 (0.046) | \*\*\*\*\* | +133.2% (+4.74%) |
| 4 | 16 | 2 | 1.42 (34.50) | −0.37 (9.75) | −0.106 (−0.008) | n.s. | −10.0% (−0.75%) |
| 5 | 32 | 1 | 1.77 (23.84) | 1.19 (19.22) | −0.240 (−0.030) | \*\* | −21.4% (−2.99%) |

*Note: Numbers outside parentheses represent results for normalized features; numbers inside parentheses represent results for raw features. The "Energy" columns list energy at all five levels of spatial resolution for these two files. The "Value of β_j" column describes the estimated beta weight in logistic regression fitting file maliciousness to the five wavelet energy values, based on n = 1599 files. P-value codes: \* = p < 0.05, \*\* = p < 0.01, \*\*\* = p < 0.001, \*\*\*\* = p < 0.0001, \*\*\*\*\* = p < 0.00001. "Malware Sensitivity" represents the estimated change in odds that a file is malware associated with a one unit increase in the corresponding feature, calculated by (e^β − 1) × 100%.*

Based on these logistic regression beta weight (β_j) values, we see that the two sample files from Figure 3 are indeed representative of a larger trend: having high energy at spatial resolution levels 1, 2 and 3 (the coarser levels) is associated with a higher probability of the file being malware (since those β_j's are positive), whereas having high energy at levels 4 and 5 (the finer levels) is associated with a lower probability of the file being malicious (since those β_j's are negative). Moreover, these associations appear to be reflective of trends in the larger population of files, since the p-values are largely strongly statistically significant. This finding makes sense if artificial encryption and compression tactics tend to elevate moderate to large sized chunks of malicious files into high entropy states.

#### 2.3.2. Suspicious Patterns of Entropic Change Across All File Size Groups

Do the trends found in the single level analysis of n = 1599 files hold up in the full corpus of n = 39,968 files? In particular, regardless of file size, can we corroborate the simply stated conclusion that "malware tends to concentrate entropic energy at relatively coarse levels of spatial resolution"? And if so, where is the dividing line between "coarse" and "fine"?

> **Figure 4** – A "Danger Map" for entropy patterns within a piece of software. The danger map is derived from a statistical model of malware classification which learns suspicious patterns inherent within each software's entropy streams. In particular, a wavelet decomposition of these entropy streams reveals the entropic energy at various levels of resolution. The plot shows logistic regression beta coefficients for determining the probability that a portable executable file is malware based upon the magnitude of file's entropic energy at various levels of resolution within the code. Positive betas (red colors) mean higher "entropic energy" at that resolution level is associated with greater probability of being malware. Negative betas (blue colors) mean higher "entropic energy" at that resolution level is associated with lower probability of being malware. Stronger intensities represent stronger magnitudes of the relationship.

Taking this Danger Map into consideration, we draw the following conclusions:

- **To a first approximation**, the full analysis supports the "coarse-energy-is-bad, fine-energy-is-good" mantra (observed in Section 2.3.1's analysis of a single file-size group). Visually, most diagonal elements of the matrix are blue (and also more blue than the off-diagonals). Thus, across most file sizes, high energies at the finest-level of spatial resolution appear to be indicative of file legitimacy, and high energies at coarse levels of spatial resolution are often associated with suspiciousness.

- **However**, what qualifies as a suspicious pattern in the wavelet decomposition of a file's entropy stream appears to be more complex than the simplistic summary above. For example, the appearance of the double diagonal bands in blue suggest somewhat regular vacillations in terms of how "suspicious" high entropic energy would look at various levels of spatial resolution. We find that the particular patterning depicted in the Danger Map provides a statistically significantly better description of malware than random (baseline-informed) guessing alone.

Likelihood ratio tests comparing the fit of the size-specific models versus the fit of models with no features yield the test statistics below. Moving from bottom (J = 3) to top (J = 15) of the figure:

χ²(3) = 198.36, χ²(4) = 563.51, χ²(5) = 257.52,
χ²(6) = 235.09, χ²(7) = 150.11, χ²(8) = 585.57,
χ²(9) = 662.22, χ²(10) = 283.24, χ²(11) = 385.33,
χ²(12) = 305.04, χ²(13) = 233.39, χ²(14) = 116.17,
χ²(15) = 61.88

All of these test statistics achieve statistical significance at the α = 0.05 level. Moreover, even after a conservative Bonferroni's correction for simultaneous hypothesis testing (of 10 null hypotheses), we can still reject the null hypothesis of a uniform color across rows for each spatial resolution except spatial resolution level 9. This finding suggests that the distribution of colors in the "Danger Map" of Figure 4, while not sufficiently simplistic to be easily verbalizable, is unlikely to be obtainable by random chance.[^3]

[^3]: We reject the null hypothesis that the colors in each row are uniform, and this rejection is consistent with the hypothesis that the complex patterns of colors are meaningful in predicting malware. However, we point out for the sake of completion that this finding is also consistent with simpler but more specific hypotheses, such as that the right-most off-diagonal cell is driving the result. Ideally, a more sophisticated statistical model, well-tailored to the structure of a multi-resolution dataset, would be applied here to tease apart these remaining possibilities.

### 2.4. Predictive Performance of the Single Wavelet Feature

How can we use the information distributed across the "Danger Map" to construct a single number which could score a piece of software's suspiciousness based on the wavelet decomposition of its entropy signal? We studied the predictive performance of SSECS in identifying malware by constructing a hold-out test set of n = 7991 files and found:

1. **SSECS as a single feature improved predictions of malware**, within a balanced sample of malware and legitimate software, from 50% to 68.7% accuracy. This makes SSECS a particularly impressive feature, considering that most machine learning models of malware consist of millions of features.

2. **SSECS provides predictive information beyond what is contained in a mean entropy feature.** A model with mean entropy as a single feature achieved 66.2% predictive accuracy. Thus, mean entropy is indeed also an impressive single predictor of malware (perhaps not surprisingly given its prevalence in the literature). However, unlike mean entropy, the wavelet energy spectrum detects suspicious patterns of entropic change across the code of the executable file. We found that a 2-feature model which includes both mean entropy and SSECS achieves 73.3% predictive accuracy (so adding wavelet-based information to the model yields a 7.1% boost in predictive accuracy beyond what is obtained by mean entropy alone).

3. **SSECS provides predictive information beyond what is contained in a "standard deviation of entropy" feature.** A skeptic might ask: why not simply use standard deviation, a more commonly used and more computationally straightforward measure of variation? Standard deviation is useful, but a relatively cruder measure of variation, as it operates on only a single spatial scale. Indeed, a 2-feature model which includes both mean entropy and standard deviation achieves merely 70.4% predictive accuracy.

---

## 3. Experiment 2: Larger-Scale Detection of Parasitic Malware

In Experiment 1, we evaluated the predictive value of a single wavelet-based feature that describes how software's entropic shifts are distributed across multiple spatial scales. We found that this feature can exploit valuable information from a software's entropy signal which is relevant to malware status and which goes beyond the predictive value of the most commonly used entropy measures, mean entropy, as well as a potentially conceptually simpler measure of entropy variation, entropy standard deviation.

In Experiment 2, we apply a broader system of wavelet-based features to a larger-scale malware prediction task. In particular, the task is to identify parasitic malware from a large corpus of otherwise good files. Parasitic malware generally infects existing files on a user's system, and the infected part of the file typically conceals itself through encryption or compression. Thus, if wavelet decomposition of software entropy indeed yields features which successfully track the presence of suspicious chunks of encrypted or compressed code, then these features should be particularly valuable for a parasitic detection task.

### 3.1. Data

Data were 699,121 samples of Portable Executable (PE) files from a Cylance repository. Of these samples, 17,605 files (2.51%) were parasitic malware, and the remaining files were legitimate software. We randomly selected 80% of the dataset for training. The remaining 20% were allocated to the test set.

### 3.2. Method

To validate the utility of wavelet features in distinguishing parasitic malware from clean software, we compared four models (in the sense of types of features extracted from executable files to feed into a machine learning classifier):

1. **Strings Model:** A strings-only model is a common way to build features for a machine learning classifier [13]. Thus, we extract the P₁ = 1,117,127 most common strings observed in our corpus and use them as binary features in a predictive model.

2. **Strings+Wavelet Model:** We would like to investigate if wavelet-based features can add predictive value to a strings only model. Because of the relatively large-scale size of the dataset (≈20× the size of Experiment 1), we streamline the feature generation process. Rather than computing SSECS, the energy spectrum suspiciousness score, which requires a nested modeling step, we follow the feature generation algorithm of Section 2.2 only up to Step (2b), computing the wavelet energy spectrum. We then represent the wavelet energy spectrum separately for each file size group. In particular, a sample with T points in its entropy stream will have J = ⌊log₂T⌋ features in its wavelet energy spectrum. If J_max is the maximum observed value of J in the dataset, then we create Σ_{J=1}^{J_max} J = J_max(J_max+1)/2 features, where any given sample with T points in its entropy stream will only have non-zero values for J = ⌊log₂T⌋ of these features (namely, for the part of the vector that corresponds to its filesize group). Although obviously this procedure creates a huge proliferation of features relative to the single SSECS feature studied in Experiment 1, the procedure is more informative and becomes more feasible as more data is collected, while simultaneously streamlining the modeling pipeline for larger datasets. Finally, we bin the wavelet energy spectrum features, which are originally continuous, to create a sparse binary dataset. In this way, we obtain 24,009 binary features derived from the wavelet energy spectrum. After adding in the strings as well, the Strings+Wavelet model includes P₂ = 1,141,136 binary features.

3. **Strings+Entropy+Wavelet Model:** The wavelet features capture some information about the entropy signal, but it is incomplete. For example, the wavelet energy spectrum describes variation at multiple levels of resolution, but ignores first-order information (i.e., measures of central tendency, such as the mean). Thus, in an attempt to construct a more powerful predictive model from strings and the entropy signal, here we add simple summary statistics about the entropy signal: mean, standard deviation, signal-to-noise ratio, maximum entropy, percentage of the signal with "high" entropy (≥6.5 bits), percentage of the signal with zero entropy, and length and squared length of the signal. As these supplementary entropy features are relatively simple to compute, we obtain these measurements separately for each PE section. As these features are also continuous, they are then binned to create a sparse binary dataset. This procedure creates 108,835 additional features to add to the strings model (24,009 derived from the wavelet energy spectrum, and 84,826 other entropy features). All together, this model contains P₃ = 1,225,962 binary features.

4. **Strings+Entropy Model:** In order to provide a more rigorous test of the value of the wavelet features, we create a fourth model which includes strings and the summary entropy features described above, but no wavelet features. Our reasoning is that, even if the wavelet features improve the strings-only model, this improvement could, in theory, have been merely driven by the inclusion of some entropy information (or even file length). By constructing this model, we can compare the performance of the Strings+Entropy+Wavelet model with the performance of the Strings+Entropy model to answer the question: do wavelet features provide additional predictive information that goes above and beyond the information inherent in summary entropy statistics (mean, max standard deviation, etc.)? Thus, this model includes the 84,826 summary entropy features, but not the wavelet features. All together, with the string features as well, this model contains P₄ = 1,201,953 features.

Because we have a large number of predictors (up to P_max = 1,225,962) relative to samples (N = 699,121), we apply a **"logistic lasso" model** (i.e. ℓ₁-penalized logistic regression) to perform classification and feature selection simultaneously. Similarly to unregularized logistic regression, we can use the learned regression (or beta) weights as a proxy for feature importance. Since the features are all binary, each β_j, j = 1, . . . , P can be interpreted as the increase in log odds that the file is malware which is associated with the jth feature "turning on" (i.e. flipping from 0 to 1) and all other features staying constant. Thus, features with large positive (respectively, negative) beta weights can be considered particularly strong predictors of goodness (respectively, badness).

In the results section, we explore properties of the most "influential" features, defined as the collection of 100 features with the largest positive weights and 100 features with the largest negative weights. As our purpose in this paper is to compare the effect of different feature subsets on predictive performance, and not to explore the predictive benefits of varying levels of sparsity in feature selection, we simply fix the sparsity parameter to 1.0.

### 3.3. Results and Discussion

> **Figure 5** – Performance boost on parasitic malware detection task caused by adding wavelet-based features to two different baseline models. Performance was measured as accuracy on a hold-out test set of software samples which a logistic lasso classifier did not see during training. The left plot shows Strings vs Strings+Wavelet; the right plot shows Strings+Entropy vs Strings+Entropy+Wavelet.

**Table 2** – Wavelet-based decomposition of software entropy boosts performance on a parasitic malware detection task. The left hand column shows the hit rate of the model, and the right hand column shows the correct rejection rate.

| Model | Parasitic Malware Detection | Clean Software Detection |
|-------|----------------------------|--------------------------|
| Strings | 80.90% | 99.64% |
| Strings+Wavelet | **82.97%** | **99.65%** |
| Strings+Entropy | 92.10% | 99.97% |
| Strings+Entropy+Wavelet | **94.27%** | **99.98%** |
| Strings+Entropy | 98.63% | 99.19% |
| Strings+Entropy+Wavelet | **98.90%** | **99.23%** |

Figure 5 (left plot) reveals that the wavelet features improved the string-only model's ability to detect parasitics while simultaneously reducing false positives. The effect of wavelet features on detection was fairly strong for most false positive rates. For example, for false positive rates around one-third of one percent, the wavelet features boosted detection of parasitic malware from 80.90% to 82.97% despite only adding ∼24k features to the original corpus of ∼1.1 million strings.

Moreover, Figure 5 (right plot) reveals that inclusion of wavelet features boosted the parasitic detection performance of a strings-plus-entropy model in a fairly pronounced way as well. For false positive rates around 0.02%–0.03%, detection of parasitic malware jumped from 92.10% to 94.27%. For false positive rates around 0.77%–0.79%, detection of parasitic malware jumped from 98.63% to 98.90%. These results in Figure 5 (right side) reinforce the conclusion of Experiment 1, where we find that wavelet features capture information that goes beyond more pedestrian entropy-based information (mean, max, standard deviation, etc.).

Overall, these results suggest that the wavelet energy spectrum extracted from the entropy signal of an executable file provides a useful set of features for a machine learning model for automatically detecting parasitic malware. Moreover, the predictive value of these features seems to not be redundant with other, simpler summary features derivable from the entropy signal.

**Table 3** – Wavelet-based features are disproportionately likely to be influential features.

| Model | % of All Features | % of Influential Features |
|-------|-------------------|---------------------------|
| Strings+Wavelet | 2.10% | 7.00% |
| Strings+Entropy+Wavelet | 1.96% | 4.50% |

In Table 3, we report some additional results about the most influential features in the various models. In the strings-only model, we found that the 100 most influential strings in terms of pushing the model towards a parasitics classification included examples such as: `CreateKernelThread`, `Trampoline`, `FreeAllBuffers`, `VVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV`, `UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU`, `SetProcessPriorityBoost`, `CreateProcessA`, and `! Best regards 2 Tommy Salo 002E [Nov-2005] yours [Dziadulja Apanas]`.

For the strings+wavelet model, we see that even though the wavelet features comprise a relatively small proportion (2.1%) of the strings+wavelet model, they constitute a relatively large proportion (7.0%) of that model's set of influential features. From an adversarial point of view, it is a nice finding that wavelet-based features can displace some of the importance of strings, as it is presumably easier for an evasive malware writer to alter a suggestive string such as `Trampoline` (the string is suspicious as it evokes derivatives of the state-sponsored Stuxnet parasitic worm) than to displace an entropic energy spectral configuration in a direction favored by a machine learning model.

Finally, in the strings+wavelet+entropy model, wavelet features were also disproportionately influential on the final classification; they were about 2.5 times more likely to be influential features than would have been predicted based on their overall prevalence in the feature corpus alone.

---

## 4. Grand Discussion

All together, wavelet decompositions of software entropy seem to be useful for malware prediction tasks by capturing the degree to which a portable executable file exhibits suspicious patterns of shifting entropy within its byte-level code. In particular, we considered the problem that certain kinds of malware (e.g. parasitic malware) tend to contain chunks of encrypted and compressed code embedded in an otherwise normal looking executable file. To address this situation, we applied a wavelet decomposition to each file's entropy stream so as to obtain each file's entropic wavelet energy spectrum. The entropic wavelet energy spectrum characterizes how a file distributes entropic change across multiple levels of spatial resolution.

In the first study, we found that a single feature derived from wavelet decompositions of software entropy can yield valuable predictive information in a heterogeneous corpus of malware. In the second study, we found that features derived from the wavelet decompositions boosted performance on a large-scale parasitic malware detection task, and that a classifier built solely on three types of features (strings+entropy+wavelet) can produce excellent predictive performance. In both studies, we found that the information provided by wavelet decompositions of software entropy is not merely redundant with more common measures such as mean entropy or standard deviation of the entropy.

### Future Research Directions

Future research relating wavelet decompositions to malware classification in machine learning tasks might consider any of the following goals:

1. **Exploit predictive value from information about the location of entropic change** (perhaps as pointers for extracting further information about those parts of the file). This location of entropic change is provided in the mother wavelet coefficients across which we have marginalized to obtain the wavelet energy spectrum.

2. **Apply a more powerful classifier**, such as a deep-learning neural network, which could consider more complicated interactions between features when modeling the response. In addition, incorporate other classes of features (n-grams [14], statistical functions of n-grams [15], etc.) What kinds of features interact usefully with the wavelet energy spectrum in predicting malware, and what can we learn from that about the existing corpus of parasitic malware? Note that the predictive performance of the model would likely improve by first applying appropriate dimensionality reduction techniques; see e.g. [16].

3. **Investigate the potential utility of non-entropic wavelet energy spectra** from byte-level representations of executable files. Indeed, entropy streams are just one possible example of real-valued streams derivable from byte-level file content (see e.g. [15]), and wavelet energy spectra can be extracted from any real-valued function on the raw bytes.

---

## References

[1] T. Brosch, M. Morgenstern, Runtime packers: The hidden problem, Black Hat USA.

[2] R. Lyda, J. Hamrock, Using entropy analysis to find encrypted and packed malware, IEEE Secur. Privacy (2) (2007) 40–45.

[3] I. Sorokin, Comparing files using structural entropy, J. Comput. Virol. 7 (4) (2011) 259–265.

[4] D. Baysa, R.M. Low, M. Stamp, Structural entropy and metamorphic malware, J. Comput. Virol. Hacking Tech. 9 (4) (2013) 179–192.

[5] M. Wojnowicz, G. Chisholm, M. Wolff, Suspiciously structured entropy: Wavelet decomposition of software entropy reveals symptoms of malware in the energy spectrum, in: The Twenty-Ninth International Flairs Conference, 2016.

[6] M. Wojnowicz, G. Chisholm, B. Wallace, M. Wolff, X. Zhao, J. Luan, SUSPEND: Determining software suspiciousness by non-stationary time series modeling of entropy signals, Expert Syst. Appl. 71 (2017) 301-218.

[7] G. Nason, Wavelet Methods in Statistics with R, Springer Science & Business Media, 2010.

[8] Y.C. Pati, P.S. Krishnaprasad, Analysis and synthesis of feedforward neural networks using discrete affine wavelet transformations, IEEE Trans. Neural Netw. 4 (1) (1993) 73–85.

[9] A. Subasi, Eeg signal classification using wavelet feature extraction and a mixture of expert model, Expert Syst. Appl. 32 (4) (2007) 1084–1093.

[10] A. Kandaswamy, C.S. Kumar, R.P. Ramanathan, S. Jayaraman, N. Malmurugan, Neural classification of lung sounds using wavelet coefficients, Comput. Biol. Med. 34 (6) (2004) 523–537.

[11] I. Omerhodzic, S. Avdakovic, A. Nuhanovic, K. Dizdarevic, Energy distribution of eeg signals: Eeg signal wavelet-neural network classifier, ArXiv Preprint arXiv:1307.7897.

[12] A. Subasi, M. Yilmaz, H.R. Ozcalik, Classification of emg signals using wavelet neural network, J. Neurosci. Methods 156 (1) (2006) 360–367.

[13] M.G. Schultz, E. Eskin, E. Zadok, S.J. Stolfo, Data mining methods for detection of new malicious executables, in: 2001 IEEE Symposium on Security and Privacy, 2001. S&P 2001. Proceedings, IEEE, 2001, pp. 38–49.

[14] J.Z. Kolter, M.A. Maloof, Learning to detect malicious executables in the wild, in: Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2004, pp. 470–478.

[15] S.M. Tabish, M.Z. Shafiq, M. Farooq, Malware detection using statistical analysis of byte-level file content, in: Proceedings of the ACM SIGKDD Workshop on CyberSecurity and Intelligence Informatics, ACM, 2009, pp. 23–31.

[16] M. Wojnowicz, D. Zhang, G. Chisholm, X. Zhao, M. Wolff, Projecting "better than randomly": How to reduce the dimensionality of very large datasets in a way that outperforms random projections. In: Data Science and Advanced Analytics (DSAA), 2016 International Conference on IEEE., 2016 (in press).

---

*© 2016 Qassim University. Production and Hosting by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).*

*DOI: http://dx.doi.org/10.1016/j.jides.2016.10.009*
