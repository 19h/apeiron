//! Wavelet Entropy Analysis
//!
//! This module provides wavelet-based entropy analysis for binary files.
//! It computes entropy at multiple frequency scales using Haar wavelet decomposition,
//! revealing structural patterns that aren't visible in simple entropy calculations.
//!
//! # Algorithm
//!
//! 1. **Entropy stream**: Split file into 256-byte chunks, compute Shannon entropy
//! 2. **Haar wavelet transform**: Decompose entropy stream into frequency scales
//! 3. **Energy spectrum**: Compute energy (sum of squared coefficients) at each scale
//!
//! The energy distribution across scales reveals file structure:
//! - High energy at coarse scales: Large-scale entropy variations (packed sections, etc.)
//! - High energy at fine scales: Local entropy fluctuations (code, structured data)
//!
//! # References
//!
//! - Haar wavelets: Piecewise constant, orthonormal basis
//! - Uses 1/√2 scaling for energy preservation

use rayon::prelude::*;

/// Default chunk size for entropy stream computation (256 bytes).
pub const DEFAULT_CHUNK_SIZE: usize = 256;

/// Minimum file size for meaningful wavelet analysis.
pub const MIN_FILE_SIZE: usize = 512;

/// Maximum number of wavelet decomposition levels.
pub const MAX_LEVELS: usize = 16;

/// Wavelet entropy analysis results.
#[derive(Debug, Clone)]
pub struct WaveletEntropyAnalysis {
    /// Chunk size used for entropy computation.
    pub chunk_size: usize,
    /// Entropy values for each chunk.
    pub entropy_stream: Vec<f64>,
    /// Number of chunks in the entropy stream.
    pub num_chunks: usize,
    /// Number of wavelet decomposition levels (J).
    pub j: usize,
    /// Wavelet coefficients at each level.
    pub coefficients: Vec<Vec<f64>>,
    /// Energy at each wavelet level.
    pub energy_spectrum: Vec<f64>,
    /// Total energy across all levels.
    pub total_energy: f64,
}

impl WaveletEntropyAnalysis {
    /// Create wavelet analysis from binary data.
    pub fn from_data(data: &[u8], chunk_size: usize) -> Self {
        let entropy_stream = compute_entropy_stream(data, chunk_size);
        let num_chunks = entropy_stream.len();

        if num_chunks < 2 {
            return Self {
                chunk_size,
                entropy_stream,
                num_chunks,
                j: 0,
                coefficients: Vec::new(),
                energy_spectrum: Vec::new(),
                total_energy: 0.0,
            };
        }

        // Compute number of levels and truncate to dyadic length
        let j = (num_chunks as f64).log2().floor() as usize;
        let n = 1usize << j;
        let truncated_stream: Vec<f64> = entropy_stream[..n].to_vec();

        // Perform Haar wavelet transform
        let coefficients = haar_wavelet_transform(&truncated_stream);

        // Compute energy spectrum
        let energy_spectrum: Vec<f64> = coefficients
            .iter()
            .map(|coeffs| coeffs.iter().map(|d| d * d).sum())
            .collect();

        let total_energy: f64 = energy_spectrum.iter().sum();

        Self {
            chunk_size,
            entropy_stream,
            num_chunks,
            j,
            coefficients,
            energy_spectrum,
            total_energy,
        }
    }

    /// Get information about each wavelet level.
    pub fn get_level_info(&self) -> Vec<LevelInfo> {
        self.energy_spectrum
            .iter()
            .enumerate()
            .map(|(level, &energy)| {
                let num_bins = 1usize << level;
                let bin_size = self.num_chunks / num_bins;
                let is_coarse = level < self.j / 2;
                LevelInfo {
                    level,
                    num_bins,
                    bin_size,
                    energy,
                    is_coarse,
                }
            })
            .collect()
    }

    /// Get energy ratio for coarse (low frequency) scales.
    pub fn coarse_energy_ratio(&self) -> f64 {
        if self.total_energy < 1e-10 || self.j == 0 {
            return 0.5;
        }
        let mid = (self.j + 1) / 2;
        let coarse: f64 = self.energy_spectrum[..mid.min(self.energy_spectrum.len())]
            .iter()
            .sum();
        coarse / self.total_energy
    }

    /// Get energy ratio for fine (high frequency) scales.
    pub fn fine_energy_ratio(&self) -> f64 {
        if self.total_energy < 1e-10 || self.j == 0 {
            return 0.5;
        }
        let mid = (self.j + 1) / 2;
        let fine: f64 = self.energy_spectrum[mid.min(self.energy_spectrum.len())..]
            .iter()
            .sum();
        fine / self.total_energy
    }
}

/// Information about a single wavelet decomposition level.
#[derive(Debug, Clone, Copy)]
pub struct LevelInfo {
    /// Level index (0 = coarsest).
    pub level: usize,
    /// Number of coefficients at this level.
    pub num_bins: usize,
    /// Size of each bin in bytes.
    pub bin_size: usize,
    /// Energy at this level.
    pub energy: f64,
    /// Whether this is a coarse (low frequency) level.
    pub is_coarse: bool,
}

/// Wavelet analysis report for a file.
#[derive(Debug, Clone)]
pub struct WaveletMalwareReport {
    /// File size in bytes.
    pub file_size_bytes: usize,
    /// File size in KB.
    pub file_size_kb: f64,
    /// Detected file type.
    pub file_type: &'static str,
    /// Chunk size used for analysis.
    pub chunk_size: usize,
    /// Number of entropy chunks.
    pub num_entropy_chunks: usize,
    /// Number of wavelet decomposition levels.
    pub num_wavelet_levels: usize,
    /// Total wavelet energy.
    pub total_wavelet_energy: f64,
    /// Energy spectrum across levels.
    pub energy_spectrum: Vec<f64>,
    /// Level-by-level information.
    pub level_info: Vec<LevelInfo>,
}

impl WaveletMalwareReport {
    /// Create a summary string of the analysis.
    pub fn summary(&self) -> String {
        let coarse_ratio = self.coarse_energy_ratio();
        let fine_ratio = self.fine_energy_ratio();

        format!(
            "File: {} ({:.1} KB, {} chunks)\n\
             Wavelet Levels: {}\n\
             Total Energy: {:.2}\n\
             Coarse Energy Ratio: {:.1}%\n\
             Fine Energy Ratio: {:.1}%",
            self.file_type,
            self.file_size_kb,
            self.num_entropy_chunks,
            self.num_wavelet_levels,
            self.total_wavelet_energy,
            coarse_ratio * 100.0,
            fine_ratio * 100.0,
        )
    }

    /// Get energy ratio for coarse (low frequency) scales.
    pub fn coarse_energy_ratio(&self) -> f64 {
        if self.total_wavelet_energy < 1e-10 || self.num_wavelet_levels == 0 {
            return 0.5;
        }
        let mid = (self.num_wavelet_levels + 1) / 2;
        let coarse: f64 = self.energy_spectrum[..mid.min(self.energy_spectrum.len())]
            .iter()
            .sum();
        coarse / self.total_wavelet_energy
    }

    /// Get energy ratio for fine (high frequency) scales.
    pub fn fine_energy_ratio(&self) -> f64 {
        if self.total_wavelet_energy < 1e-10 || self.num_wavelet_levels == 0 {
            return 0.5;
        }
        let mid = (self.num_wavelet_levels + 1) / 2;
        let fine: f64 = self.energy_spectrum[mid.min(self.energy_spectrum.len())..]
            .iter()
            .sum();
        fine / self.total_wavelet_energy
    }
}

/// Compute Shannon entropy for a chunk of bytes.
#[inline]
fn chunk_entropy(chunk: &[u8]) -> f64 {
    if chunk.is_empty() {
        return 0.0;
    }

    let mut counts = [0u32; 256];
    for &byte in chunk {
        counts[byte as usize] += 1;
    }

    let total = chunk.len() as f64;
    let mut entropy = 0.0;

    for &count in &counts {
        if count > 0 {
            let p = count as f64 / total;
            entropy -= p * p.log2();
        }
    }

    entropy
}

/// Compute entropy stream from binary data.
pub fn compute_entropy_stream(data: &[u8], chunk_size: usize) -> Vec<f64> {
    if data.is_empty() {
        return Vec::new();
    }

    let num_chunks = (data.len() + chunk_size - 1) / chunk_size;
    let mut stream = Vec::with_capacity(num_chunks);

    for i in 0..num_chunks {
        let start = i * chunk_size;
        let end = (start + chunk_size).min(data.len());
        stream.push(chunk_entropy(&data[start..end]));
    }

    stream
}

/// Compute entropy stream in parallel (for large files).
pub fn compute_entropy_stream_par(data: &[u8], chunk_size: usize) -> Vec<f64> {
    if data.is_empty() {
        return Vec::new();
    }

    let num_chunks = (data.len() + chunk_size - 1) / chunk_size;

    (0..num_chunks)
        .into_par_iter()
        .map(|i| {
            let start = i * chunk_size;
            let end = (start + chunk_size).min(data.len());
            chunk_entropy(&data[start..end])
        })
        .collect()
}

/// Perform Haar wavelet transform on a signal.
///
/// Returns detail coefficients at each level, ordered from coarsest to finest.
/// Uses orthonormal scaling (1/√2) for energy preservation.
pub fn haar_wavelet_transform(signal: &[f64]) -> Vec<Vec<f64>> {
    if signal.is_empty() {
        return Vec::new();
    }

    let j = (signal.len() as f64).log2().floor() as usize;
    if j == 0 {
        return Vec::new();
    }

    let n = 1usize << j;
    let mut data: Vec<f64> = signal[..n].to_vec();

    let mut coefficients: Vec<Vec<f64>> = Vec::with_capacity(j);

    let mut current_len = n;

    while current_len > 1 {
        let half = current_len / 2;
        let mut details = Vec::with_capacity(half);

        // Compute detail coefficients (high-pass filter)
        for i in 0..half {
            let left = data[2 * i];
            let right = data[2 * i + 1];
            // Orthonormal Haar: divide by √2
            let diff = (left - right) / 2.0_f64.sqrt();
            details.push(diff);
        }

        coefficients.push(details);

        // Compute averages (low-pass filter)
        let mut averages = Vec::with_capacity(half);
        for i in 0..half {
            let avg = (data[2 * i] + data[2 * i + 1]) / 2.0_f64.sqrt();
            averages.push(avg);
        }

        data = averages;
        current_len = half;
    }

    // Reverse to get coarsest level first
    coefficients.reverse();
    coefficients
}

/// Compute wavelet energy spectrum from coefficients.
pub fn compute_wavelet_energy_spectrum(coefficients: &[Vec<f64>]) -> Vec<f64> {
    coefficients
        .iter()
        .map(|level| level.iter().map(|d| d * d).sum())
        .collect()
}

/// Analyze file and produce wavelet report.
pub fn analyze_file_for_wavelet(data: &[u8]) -> WaveletMalwareReport {
    let analysis = WaveletEntropyAnalysis::from_data(data, DEFAULT_CHUNK_SIZE);

    let file_size_kb = data.len() as f64 / 1024.0;
    let file_type = identify_file_type(data);
    let level_info = analysis.get_level_info();

    WaveletMalwareReport {
        file_size_bytes: data.len(),
        file_size_kb,
        file_type,
        chunk_size: analysis.chunk_size,
        num_entropy_chunks: analysis.num_chunks,
        num_wavelet_levels: analysis.j,
        total_wavelet_energy: analysis.total_energy,
        energy_spectrum: analysis.energy_spectrum,
        level_info,
    }
}

/// Identify file type from magic bytes.
pub fn identify_file_type(data: &[u8]) -> &'static str {
    if data.len() < 4 {
        return "Unknown";
    }

    if data.starts_with(&[0x4D, 0x5A]) {
        "PE/EXE"
    } else if data.starts_with(&[0x7F, 0x45, 0x4C, 0x46]) {
        "ELF"
    } else if data.starts_with(&[0xFE, 0xED, 0xFA, 0xCE])
        || data.starts_with(&[0xCE, 0xFA, 0xED, 0xFE])
    {
        "Mach-O"
    } else if data.starts_with(&[0x25, 0x50, 0x44, 0x46]) {
        "PDF"
    } else if data.starts_with(&[0x50, 0x4B, 0x03, 0x04]) {
        "ZIP"
    } else if data.starts_with(&[0x89, 0x50, 0x4E, 0x47]) {
        "PNG"
    } else if data.starts_with(&[0xFF, 0xD8, 0xFF]) {
        "JPEG"
    } else {
        "Binary"
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_entropy_stream() {
        let data: Vec<u8> = (0..512).map(|i| (i % 256) as u8).collect();
        let stream = compute_entropy_stream(&data, 256);
        assert_eq!(stream.len(), 2);
        // Full byte range should have high entropy (close to 8.0)
        assert!(stream[0] > 7.9);
    }

    #[test]
    fn test_entropy_stream_random() {
        let data: Vec<u8> = (0..1024).map(|i| ((i * 17 + 31) % 256) as u8).collect();
        let stream = compute_entropy_stream(&data, 256);
        assert_eq!(stream.len(), 4);
        for &entropy in &stream {
            assert!(entropy > 0.0 && entropy <= 8.0);
        }
    }

    #[test]
    fn test_haar_transform() {
        let signal = vec![1.0, 2.0, 3.0, 4.0];
        let coeffs = haar_wavelet_transform(&signal);
        assert_eq!(coeffs.len(), 2);
        // Level 0 (coarsest): 1 coefficient
        assert_eq!(coeffs[0].len(), 1);
        // Level 1 (finest): 2 coefficients
        assert_eq!(coeffs[1].len(), 2);
    }

    #[test]
    fn test_haar_orthonormal_energy_preservation() {
        // Use a signal with varying values to get non-zero coefficients
        let signal: Vec<f64> = vec![1.0, 3.0, 2.0, 6.0, 4.0, 8.0, 5.0, 7.0];

        let coeffs = haar_wavelet_transform(&signal);
        let wavelet_energy: f64 = coeffs.iter().flat_map(|c| c.iter()).map(|d| d * d).sum();

        // The detail coefficients capture the variation in the signal
        // Energy should be positive for a non-constant signal
        assert!(
            wavelet_energy > 0.0,
            "Wavelet energy should be positive for varying signal: {}",
            wavelet_energy
        );
    }

    #[test]
    fn test_wavelet_energy_spectrum() {
        // Create data with varying entropy across chunks
        // Mix of low-entropy (zeros) and high-entropy (varied) sections
        let mut data = Vec::with_capacity(2048);
        for i in 0..8 {
            if i % 2 == 0 {
                // Low entropy chunk (all same value)
                data.extend(std::iter::repeat(0u8).take(256));
            } else {
                // Higher entropy chunk (varied values)
                data.extend((0..256).map(|j| ((i * 37 + j * 17) % 256) as u8));
            }
        }

        let analysis = WaveletEntropyAnalysis::from_data(&data, 256);

        assert!(!analysis.energy_spectrum.is_empty());
        // With alternating low/high entropy, we should have wavelet energy
        assert!(
            analysis.total_energy > 0.0,
            "Expected non-zero wavelet energy for varied data"
        );
    }

    #[test]
    fn test_identify_file_type() {
        assert_eq!(identify_file_type(&[0x4D, 0x5A, 0x00, 0x00]), "PE/EXE");
        assert_eq!(identify_file_type(&[0x7F, 0x45, 0x4C, 0x46]), "ELF");
        assert_eq!(identify_file_type(&[0x89, 0x50, 0x4E, 0x47]), "PNG");
        assert_eq!(identify_file_type(&[0x00, 0x00, 0x00, 0x00]), "Binary");
    }
}
