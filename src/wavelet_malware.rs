//! Wavelet-Based Malware Detection
//!
//! Implementation of the Suspiciously Structured Entropic Change Score (SSECS)
//! methodology from: "Wavelet Decomposition of Software Entropy Reveals Symptoms of Malicious Code"
//! Wojnowicz et al., Journal of Innovation in Digital Ecosystems 3 (2016) 130-140
//!
//! # Paper Summary
//!
//! Key insight: Malware concentrates entropic energy at COARSE spatial resolution levels
//! (large entropy shifts between encrypted/compressed sections), while legitimate files
//! concentrate energy at FINE spatial resolution levels.
//!
//! The paper defines SSECS as a malware probability score computed via:
//! 1. Entropy stream: Split file into 256-byte chunks, compute Shannon entropy (Eq. 4)
//! 2. Haar wavelet transform: Compute detail coefficients d_{jk} at multiple scales (Eq. 5)
//! 3. Energy spectrum: E_j = Σ(d_{jk})² for each resolution level j (Eq. 3)
//! 4. Logistic regression: P_malware = 1/(1 + exp[-(β₀ + E·β)]) with trained weights
//!
//! # Implementation Details
//!
//! **Matches paper:**
//! - Entropy computation: 256-byte chunks, Shannon entropy H = -Σp log₂p (Eq. 4)
//! - Orthonormal Haar wavelet: Uses 1/√2 scaling for both detail and average (energy-preserving)
//! - Energy spectrum: Sum of squared coefficients per level (Eq. 3)
//! - J calculation: J = floor(log₂T) with right-truncation to dyadic length
//! - Level ordering: Level 0 = coarsest (1 coeff), Level J-1 = finest (2^{J-1} coeffs)
//!
//! **Deviations from paper:**
//! - SSECS model: Uses heuristic weights instead of trained logistic regression coefficients.
//!   The paper trained separate models for each file-size group (the "Danger Map", Figure 4)
//!   using labeled malware/benign samples. We lack this training data.
//! - Feature space: Uses coarse/fine energy RATIOS rather than raw energy values, since
//!   ratios are more robust across file sizes without per-size-group calibration.
//! - No Danger Map: Single universal model instead of file-size-specific β coefficients.
//!
//! # References
//!
//! - Paper: <https://doi.org/10.1016/j.jides.2016.10.009>
//! - Haar wavelets: Piecewise constant, orthonormal basis with scaling ψ_{j,k}(t) = 2^{j/2}ψ(2^j t - k)
//!
//! # This module provides:
//! - Entropy stream computation from binary data
//! - Haar wavelet decomposition with orthonormal scaling
//! - Wavelet energy spectrum extraction
//! - Heuristic SSECS calculation (approximates paper's trained model)
//! - File size grouping for multi-scale analysis

use rayon::prelude::*;
use std::collections::HashMap;

pub const DEFAULT_CHUNK_SIZE: usize = 256;
pub const MIN_FILE_SIZE: usize = 512;
pub const MAX_LEVELS: usize = 16;

#[derive(Debug, Clone)]
pub struct WaveletEntropyAnalysis {
    pub chunk_size: usize,
    pub entropy_stream: Vec<f64>,
    pub num_chunks: usize,
    pub j: usize,
    pub coefficients: Vec<Vec<f64>>,
    pub energy_spectrum: Vec<f64>,
    pub total_energy: f64,
    pub ssecs: SSECSResult,
}

#[derive(Debug, Clone)]
pub struct SSECSResult {
    pub ssecs_score: f64,
    pub probability_malware: f64,
    pub coarse_energy_ratio: f64,
    pub fine_energy_ratio: f64,
    pub energy_by_level: Vec<(usize, f64)>,
    pub classification: MalwareClassification,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MalwareClassification {
    Clean,
    Suspicious,
    LikelyMalware,
    Unknown,
}

impl SSECSResult {
    pub fn to_color(&self) -> [u8; 3] {
        let t = self.probability_malware.clamp(0.0, 1.0);
        match self.classification {
            MalwareClassification::Clean => {
                let s = t * 2.0;
                [
                    (0.1 + s * 0.1) as u8,
                    (0.4 + s * 0.4) as u8,
                    (0.8 - s * 0.3) as u8,
                ]
            }
            MalwareClassification::Suspicious => {
                let s = (t - 0.25) / 0.25;
                [
                    (0.2 + s * 0.3) as u8,
                    (0.8 - s * 0.3) as u8,
                    (0.5 - s * 0.3) as u8,
                ]
            }
            MalwareClassification::LikelyMalware => {
                let s = (t - 0.5) / 0.5;
                [
                    255,
                    ((0.5 - s * 0.5) * 255.0) as u8,
                    ((0.2 + s * 0.3) * 255.0) as u8,
                ]
            }
            MalwareClassification::Unknown => [128, 128, 128],
        }
    }
}

#[derive(Debug, Clone)]
pub struct WaveletCoefficients {
    pub level: usize,
    pub num_coefficients: usize,
    pub coefficients: Vec<f64>,
    pub energy: f64,
}

impl WaveletEntropyAnalysis {
    pub fn from_data(data: &[u8], chunk_size: usize) -> Self {
        let entropy_stream = compute_entropy_stream(data, chunk_size);
        let num_chunks = entropy_stream.len();

        if num_chunks < 2 {
            return Self {
                chunk_size,
                entropy_stream,
                num_chunks,
                j: 0,
                coefficients: Vec::new(),
                energy_spectrum: Vec::new(),
                total_energy: 0.0,
                ssecs: SSECSResult {
                    ssecs_score: 0.5,
                    probability_malware: 0.5,
                    coarse_energy_ratio: 0.5,
                    fine_energy_ratio: 0.5,
                    energy_by_level: Vec::new(),
                    classification: MalwareClassification::Unknown,
                },
            };
        }

        let j = (num_chunks as f64).log2().floor() as usize;
        let n = 1usize << j;
        let truncated_stream: Vec<f64> = entropy_stream[..n].to_vec();

        let coefficients = haar_wavelet_transform(&truncated_stream);
        let energy_spectrum: Vec<f64> = coefficients
            .iter()
            .map(|coeffs| {
                let energy: f64 = coeffs.iter().map(|d| d * d).sum();
                energy
            })
            .collect();

        let total_energy: f64 = energy_spectrum.iter().sum();
        let energy_spectrum_clone = energy_spectrum.clone();

        let ssecs = compute_ssecs(&energy_spectrum_clone, j);

        Self {
            chunk_size,
            entropy_stream,
            num_chunks,
            j,
            coefficients,
            energy_spectrum,
            total_energy,
            ssecs,
        }
    }

    pub fn get_level_info(&self) -> Vec<LevelInfo> {
        self.energy_spectrum
            .iter()
            .enumerate()
            .map(|(level, &energy)| {
                let num_bins = 1usize << level;
                let bin_size = self.num_chunks / num_bins;
                let is_coarse = level < self.j / 2;
                LevelInfo {
                    level,
                    num_bins,
                    bin_size,
                    energy,
                    is_coarse,
                }
            })
            .collect()
    }
}

#[derive(Debug, Clone, Copy)]
pub struct LevelInfo {
    pub level: usize,
    pub num_bins: usize,
    pub bin_size: usize,
    pub energy: f64,
    pub is_coarse: bool,
}

#[inline]
fn chunk_entropy(chunk: &[u8]) -> f64 {
    if chunk.is_empty() {
        return 0.0;
    }

    let mut counts = [0u32; 256];
    for &byte in chunk {
        counts[byte as usize] += 1;
    }

    let total = chunk.len() as f64;
    let mut entropy = 0.0;

    for &count in &counts {
        if count > 0 {
            let p = count as f64 / total;
            entropy -= p * p.log2();
        }
    }

    entropy
}

pub fn compute_entropy_stream(data: &[u8], chunk_size: usize) -> Vec<f64> {
    if data.is_empty() {
        return Vec::new();
    }

    let num_chunks = (data.len() + chunk_size - 1) / chunk_size;
    let mut stream = Vec::with_capacity(num_chunks);

    for i in 0..num_chunks {
        let start = i * chunk_size;
        let end = (start + chunk_size).min(data.len());
        stream.push(chunk_entropy(&data[start..end]));
    }

    stream
}

pub fn compute_entropy_stream_par(data: &[u8], chunk_size: usize) -> Vec<f64> {
    if data.is_empty() {
        return Vec::new();
    }

    let num_chunks = (data.len() + chunk_size - 1) / chunk_size;

    (0..num_chunks)
        .into_par_iter()
        .map(|i| {
            let start = i * chunk_size;
            let end = (start + chunk_size).min(data.len());
            chunk_entropy(&data[start..end])
        })
        .collect()
}

pub fn haar_wavelet_transform(signal: &[f64]) -> Vec<Vec<f64>> {
    if signal.is_empty() {
        return Vec::new();
    }

    let j = (signal.len() as f64).log2().floor() as usize;
    if j == 0 {
        return Vec::new();
    }

    let n = 1usize << j;
    let mut data: Vec<f64> = signal[..n].to_vec();

    let mut coefficients: Vec<Vec<f64>> = Vec::with_capacity(j);

    let mut current_len = n;

    while current_len > 1 {
        let half = current_len / 2;
        let mut details = Vec::with_capacity(half);

        for i in 0..half {
            let left = data[2 * i];
            let right = data[2 * i + 1];
            let diff = (left - right) / 2.0_f64.sqrt();
            details.push(diff);
        }

        coefficients.push(details);
        let mut averages = Vec::with_capacity(half);

        // Use /√2 for orthonormal Haar wavelet (energy-preserving)
        // Paper Eq. 5 uses sums with scaling s_j = (√2)^{J-j+1}
        // Orthonormal Haar with /√2 produces equivalent energy distribution
        for i in 0..half {
            let avg = (data[2 * i] + data[2 * i + 1]) / 2.0_f64.sqrt();
            averages.push(avg);
        }

        data = averages;
        current_len = half;
    }

    coefficients.reverse();
    coefficients
}

#[inline]
pub fn haar_wavelet_transform_inplace(signal: &mut [f64]) {
    let len = signal.len();
    if len < 2 {
        return;
    }

    let mut current_len = len;
    let mut temp = Vec::with_capacity(len / 2);

    while current_len > 1 {
        let half = current_len / 2;
        temp.clear();

        for i in 0..half {
            let left = signal[2 * i];
            let right = signal[2 * i + 1];
            // Use /√2 for both to match orthonormal Haar (energy-preserving)
            let avg = (left + right) / 2.0_f64.sqrt();
            let diff = (left - right) / 2.0_f64.sqrt();
            temp.push(diff);
            signal[i] = avg;
        }

        for (i, &detail) in temp.iter().enumerate() {
            signal[half + i] = detail;
        }

        current_len = half;
    }
}

pub fn compute_wavelet_energy_spectrum(coefficients: &[Vec<f64>]) -> Vec<f64> {
    coefficients
        .iter()
        .map(|level| level.iter().map(|d| d * d).sum())
        .collect()
}

pub fn compute_ssecs(energy_spectrum: &[f64], j: usize) -> SSECSResult {
    let num_levels = energy_spectrum.len();

    if num_levels == 0 {
        return SSECSResult {
            ssecs_score: 0.5,
            probability_malware: 0.5,
            coarse_energy_ratio: 0.5,
            fine_energy_ratio: 0.5,
            energy_by_level: Vec::new(),
            classification: MalwareClassification::Unknown,
        };
    }

    let total_energy: f64 = energy_spectrum.iter().sum();
    let energy_by_level: Vec<(usize, f64)> = energy_spectrum
        .iter()
        .enumerate()
        .map(|(l, &e)| (l, e))
        .collect();

    if total_energy < 1e-10 {
        return SSECSResult {
            ssecs_score: 0.5,
            probability_malware: 0.5,
            coarse_energy_ratio: 0.5,
            fine_energy_ratio: 0.5,
            energy_by_level,
            classification: MalwareClassification::Unknown,
        };
    }

    let coarse_threshold = (j + 1) / 2;
    let coarse_energy: f64 = energy_spectrum[..coarse_threshold].iter().sum();
    let fine_energy: f64 = energy_spectrum[coarse_threshold..].iter().sum();

    let coarse_ratio = coarse_energy / total_energy;
    let fine_ratio = fine_energy / total_energy;

    let probability_malware = logistic_sscecs(coarse_ratio, fine_ratio, energy_spectrum);

    let ssecs_score = probability_malware;

    let classification = if probability_malware < 0.35 {
        MalwareClassification::Clean
    } else if probability_malware < 0.65 {
        MalwareClassification::Suspicious
    } else {
        MalwareClassification::LikelyMalware
    };

    SSECSResult {
        ssecs_score,
        probability_malware,
        coarse_energy_ratio: coarse_ratio,
        fine_energy_ratio: fine_ratio,
        energy_by_level,
        classification,
    }
}

#[inline]
fn logistic_sscecs(coarse_ratio: f64, fine_ratio: f64, energy_spectrum: &[f64]) -> f64 {
    let beta_coarse = 0.8;
    let beta_fine = -0.6;
    let intercept = -0.2;

    let logit = intercept + beta_coarse * coarse_ratio + beta_fine * fine_ratio;

    let mut weighted_sum = 0.0;
    let mid_level = energy_spectrum.len() / 2;
    for (i, &energy) in energy_spectrum.iter().enumerate().take(mid_level) {
        if i < mid_level / 2 {
            weighted_sum += energy * 0.3;
        } else {
            weighted_sum -= energy * 0.2;
        }
    }

    let adjusted_logit = logit + weighted_sum / 1000.0;

    1.0 / (1.0 + (-adjusted_logit).exp())
}

#[inline]
fn logistic(x: f64) -> f64 {
    1.0 / (1.0 + (-x).exp())
}

pub struct LogisticRegression {
    weights: Vec<f64>,
    intercept: f64,
}

impl LogisticRegression {
    pub fn new(num_features: usize) -> Self {
        Self {
            weights: vec![0.0; num_features],
            intercept: 0.0,
        }
    }

    pub fn fit(
        &mut self,
        features: &[Vec<f64>],
        labels: &[bool],
        learning_rate: f64,
        iterations: usize,
    ) {
        let n = features.len();
        if n == 0 {
            return;
        }

        let m = features[0].len();
        if m == 0 {
            return;
        }

        for _ in 0..iterations {
            let mut gradient_weights = vec![0.0; m];
            let mut gradient_intercept = 0.0;

            for (feature, &label) in features.iter().zip(labels) {
                let prediction = self.predict_probability(feature);
                let error = prediction - if label { 1.0 } else { 0.0 };

                for (j, &x) in feature.iter().enumerate() {
                    gradient_weights[j] += error * x;
                }
                gradient_intercept += error;
            }

            for j in 0..m {
                self.weights[j] -= learning_rate * gradient_weights[j] / n as f64;
            }
            self.intercept -= learning_rate * gradient_intercept / n as f64;
        }
    }

    pub fn predict_probability(&self, features: &[f64]) -> f64 {
        let mut logit = self.intercept;
        for (i, &x) in features.iter().enumerate() {
            logit += self.weights[i] * x;
        }
        logistic(logit)
    }

    pub fn predict(&self, features: &[f64]) -> bool {
        self.predict_probability(features) >= 0.5
    }
}

pub struct SSECSTrainer {
    pub coarse_weight: f64,
    pub fine_weight: f64,
    pub intercept: f64,
}

impl SSECSTrainer {
    pub fn new() -> Self {
        Self {
            coarse_weight: 0.0,
            fine_weight: 0.0,
            intercept: 0.0,
        }
    }

    pub fn train(&mut self, samples: &[WaveletSample]) {
        let mut regression = LogisticRegression::new(3);

        let features: Vec<Vec<f64>> = samples
            .iter()
            .map(|s| vec![s.coarse_ratio, s.fine_ratio, s.total_energy])
            .collect();
        let labels: Vec<bool> = samples.iter().map(|s| s.is_malware).collect();

        if features.len() < 10 {
            return;
        }

        regression.fit(&features, &labels, 0.1, 1000);

        self.coarse_weight = regression.weights[0];
        self.fine_weight = regression.weights[1];
        self.intercept = regression.intercept;
    }

    pub fn predict(&self, coarse_ratio: f64, fine_ratio: f64, total_energy: f64) -> f64 {
        let mut logit = self.intercept;
        logit += self.coarse_weight * coarse_ratio;
        logit += self.fine_weight * fine_ratio;
        logit += 0.001 * total_energy;
        logistic(logit)
    }
}

#[derive(Debug, Clone)]
pub struct WaveletSample {
    pub is_malware: bool,
    pub coarse_ratio: f64,
    pub fine_ratio: f64,
    pub total_energy: f64,
    pub energy_spectrum: Vec<f64>,
}

pub fn analyze_file_for_malware(data: &[u8]) -> WaveletMalwareReport {
    let analysis = WaveletEntropyAnalysis::from_data(data, DEFAULT_CHUNK_SIZE);

    let file_size_kb = data.len() as f64 / 1024.0;
    let file_type = identify_file_type(data);

    let ssecs = analysis.ssecs.clone();
    let level_info = analysis.get_level_info();

    WaveletMalwareReport {
        file_size_bytes: data.len(),
        file_size_kb,
        file_type,
        chunk_size: analysis.chunk_size,
        num_entropy_chunks: analysis.num_chunks,
        num_wavelet_levels: analysis.j,
        total_wavelet_energy: analysis.total_energy,
        ssecs,
        level_info,
    }
}

#[derive(Debug, Clone)]
pub struct WaveletMalwareReport {
    pub file_size_bytes: usize,
    pub file_size_kb: f64,
    pub file_type: &'static str,
    pub chunk_size: usize,
    pub num_entropy_chunks: usize,
    pub num_wavelet_levels: usize,
    pub total_wavelet_energy: f64,
    pub ssecs: SSECSResult,
    pub level_info: Vec<LevelInfo>,
}

impl WaveletMalwareReport {
    pub fn is_suspicious(&self) -> bool {
        self.ssecs.probability_malware > 0.5
    }

    pub fn summary(&self) -> String {
        format!(
            "File: {} ({} KB, {} chunks)\n\
             Type: {}\n\
             Wavelet Levels: {}\n\
             Total Energy: {:.2}\n\
             SSECS Score: {:.3}\n\
             Malware Probability: {:.1}%\n\
             Classification: {:?}\n\
             Coarse Energy Ratio: {:.2}\n\
             Fine Energy Ratio: {:.2}",
            self.file_type,
            format!("{:.1}", self.file_size_kb),
            self.num_entropy_chunks,
            self.file_type,
            self.num_wavelet_levels,
            self.total_wavelet_energy,
            self.ssecs.ssecs_score,
            self.ssecs.probability_malware * 100.0,
            self.ssecs.classification,
            self.ssecs.coarse_energy_ratio,
            self.ssecs.fine_energy_ratio,
        )
    }
}

pub fn identify_file_type(data: &[u8]) -> &'static str {
    if data.len() < 4 {
        return "Unknown";
    }

    if data.starts_with(&[0x4D, 0x5A]) {
        "PE/EXE"
    } else if data.starts_with(&[0x7F, 0x45, 0x4C, 0x46]) {
        "ELF"
    } else if data.starts_with(&[0xFE, 0xED, 0xFA, 0xCE])
        || data.starts_with(&[0xCE, 0xFA, 0xED, 0xFE])
    {
        "Mach-O"
    } else if data.starts_with(&[0x25, 0x50, 0x44, 0x46]) {
        "PDF"
    } else if data.starts_with(&[0x50, 0x4B, 0x03, 0x04]) {
        "ZIP"
    } else if data.starts_with(&[0x89, 0x50, 0x4E, 0x47]) {
        "PNG"
    } else if data.starts_with(&[0xFF, 0xD8, 0xFF]) {
        "JPEG"
    } else {
        "Binary"
    }
}

pub fn batch_analyze(files: &[(&[u8], bool)]) -> Vec<(bool, f64)> {
    files
        .par_iter()
        .map(|(data, _is_malware)| {
            let analysis = WaveletEntropyAnalysis::from_data(data, DEFAULT_CHUNK_SIZE);
            let is_malware = analysis.ssecs.probability_malware > 0.5;
            (is_malware, analysis.ssecs.probability_malware)
        })
        .collect()
}

pub fn compute_danger_map(files: &[(&[u8], bool)]) -> DangerMap {
    let mut size_groups: HashMap<usize, Vec<WaveletSample>> = HashMap::new();

    for (data, _is_malware) in files {
        let analysis = WaveletEntropyAnalysis::from_data(data, DEFAULT_CHUNK_SIZE);
        let j = analysis.j;
        let energy_spectrum = analysis.energy_spectrum.clone();

        if energy_spectrum.is_empty() {
            continue;
        }

        let total_energy: f64 = energy_spectrum.iter().sum();
        let coarse_threshold = (j + 1) / 2;
        let coarse_energy: f64 = energy_spectrum[..coarse_threshold].iter().sum();
        let fine_energy: f64 = energy_spectrum[coarse_threshold..].iter().sum();

        let ssecs = analysis.ssecs;

        let sample = WaveletSample {
            is_malware: ssecs.probability_malware > 0.5,
            coarse_ratio: ssecs.coarse_energy_ratio,
            fine_ratio: ssecs.fine_energy_ratio,
            total_energy,
            energy_spectrum,
        };

        size_groups.entry(j).or_insert_with(Vec::new).push(sample);
    }

    let mut beta_coefficients: HashMap<usize, (f64, f64, f64)> = HashMap::new();

    for (&j, samples) in &size_groups {
        if samples.len() < 10 {
            continue;
        }

        let mut trainer = SSECSTrainer::new();
        trainer.train(samples);

        beta_coefficients.insert(
            j,
            (
                trainer.coarse_weight,
                trainer.fine_weight,
                trainer.intercept,
            ),
        );
    }

    DangerMap {
        size_groups,
        beta_coefficients,
    }
}

#[derive(Debug, Clone)]
pub struct DangerMap {
    pub size_groups: HashMap<usize, Vec<WaveletSample>>,
    pub beta_coefficients: HashMap<usize, (f64, f64, f64)>,
}

impl DangerMap {
    pub fn get_beta_for_size(&self, j: usize) -> Option<(f64, f64, f64)> {
        self.beta_coefficients.get(&j).copied()
    }

    pub fn visualize(&self) -> String {
        let mut output = String::new();
        output.push_str("Danger Map (β coefficients by file size group):\n");
        output.push_str("J\tCoarse(Fine)\tIntercept\tN\n");
        output.push_str("--\t------------\t---------\t--\n");

        let mut sizes: Vec<_> = self.beta_coefficients.keys().collect();
        sizes.sort();

        for &j in &sizes {
            if let Some((beta_coarse, beta_fine, intercept)) = self.beta_coefficients.get(&j) {
                let n = self.size_groups.get(&j).map(|s| s.len()).unwrap_or(0);
                output.push_str(&format!(
                    "{}\t{:.3}/{:.3}\t{:.3}\t{}\n",
                    j, beta_coarse, beta_fine, intercept, n
                ));
            }
        }

        output
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_entropy_stream() {
        let data = vec![0u8; 1024];
        let stream = compute_entropy_stream(&data, 256);
        assert_eq!(stream.len(), 4);
        for &entropy in &stream {
            assert!(entropy < 0.1, "Uniform data should have near-zero entropy");
        }
    }

    #[test]
    fn test_entropy_stream_random() {
        let data: Vec<u8> = (0..=255).cycle().take(1024).collect();
        let stream = compute_entropy_stream(&data, 256);
        assert_eq!(stream.len(), 4);
        for &entropy in &stream {
            assert!(entropy > 7.5, "Random data should have high entropy");
        }
    }

    #[test]
    fn test_haar_transform() {
        let signal: Vec<f64> = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
        let coefficients = haar_wavelet_transform(&signal);

        assert_eq!(coefficients.len(), 3);

        assert_eq!(coefficients[0].len(), 1);
        assert_eq!(coefficients[1].len(), 2);
        assert_eq!(coefficients[2].len(), 4);
    }

    #[test]
    fn test_wavelet_energy_spectrum() {
        let signal: Vec<f64> = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
        let coefficients = haar_wavelet_transform(&signal);
        let energy = compute_wavelet_energy_spectrum(&coefficients);

        assert_eq!(energy.len(), 3);
        for &e in &energy {
            assert!(e >= 0.0, "Energy should be non-negative");
        }
    }

    #[test]
    fn test_ssecs_clean_file() {
        let clean_stream: Vec<f64> = vec![
            5.0, 5.1, 5.0, 5.2, 5.1, 5.0, 5.1, 5.0, 5.0, 5.1, 5.0, 5.1, 5.0, 5.1, 5.0, 5.1,
        ];
        let coefficients = haar_wavelet_transform(&clean_stream);
        let energy = compute_wavelet_energy_spectrum(&coefficients);
        let ssecs = compute_ssecs(&energy, 4);

        assert!(
            ssecs.probability_malware < 0.5,
            "Clean file should have low malware probability"
        );
    }

    #[test]
    fn test_ssecs_malicious_pattern() {
        let malicious_stream: Vec<f64> = vec![
            2.0, 2.0, 2.0, 2.0, 7.5, 7.5, 7.5, 7.5, 2.0, 2.0, 2.0, 2.0, 7.5, 7.5, 7.5, 7.5,
        ];
        let coefficients = haar_wavelet_transform(&malicious_stream);
        let energy = compute_wavelet_energy_spectrum(&coefficients);
        let ssecs = compute_ssecs(&energy, 4);

        assert!(
            ssecs.probability_malware > 0.5,
            "Malicious pattern should have high malware probability"
        );
    }

    #[test]
    fn test_logistic_regression() {
        let mut regression = LogisticRegression::new(2);

        let features: Vec<Vec<f64>> = vec![
            vec![0.1, 0.9],
            vec![0.2, 0.8],
            vec![0.3, 0.7],
            vec![0.7, 0.3],
            vec![0.8, 0.2],
            vec![0.9, 0.1],
        ];
        let labels = vec![false, false, false, true, true, true];

        regression.fit(&features, &labels, 0.5, 500);

        assert!(regression.predict_probability(&vec![0.15, 0.85]) < 0.5);
        assert!(regression.predict_probability(&vec![0.85, 0.15]) > 0.5);
    }

    #[test]
    fn test_batch_analysis() {
        let data1 = vec![0u8; 1024];
        let data2 = vec![0x42u8; 1024];
        let files: Vec<(&[u8], bool)> = vec![(&data1, false), (&data2, false)];

        let results = batch_analyze(&files);
        assert_eq!(results.len(), 2);
    }

    #[test]
    fn test_identify_file_type() {
        assert_eq!(identify_file_type(&[0x4D, 0x5A, 0x00, 0x00]), "PE/EXE");
        assert_eq!(identify_file_type(&[0x7F, 0x45, 0x4C, 0x46]), "ELF");
        assert_eq!(identify_file_type(&[0x89, 0x50, 0x4E, 0x47]), "PNG");
    }

    /// Validates orthonormal Haar wavelet matches paper's energy formula.
    /// Paper Eq. 5: d_{kj} = (1/s_j) * (sum_right - sum_left) where s_j = (√2)^{J-j+1}
    /// For orthonormal Haar, this is equivalent to iterative (a±b)/√2 scaling.
    #[test]
    fn test_haar_orthonormal_energy_preservation() {
        // Test that orthonormal Haar preserves total energy
        let signal: Vec<f64> = vec![1.0, 2.0, 3.0, 4.0];
        let original_energy: f64 = signal.iter().map(|x| x * x).sum(); // 1+4+9+16 = 30

        let coefficients = haar_wavelet_transform(&signal);
        let wavelet_energy: f64 = coefficients
            .iter()
            .flat_map(|level| level.iter())
            .map(|d| d * d)
            .sum();

        // With orthonormal Haar, wavelet energy + final average² = original energy
        // Final average after 2 levels: (1+2+3+4) / 2 = 5 (with /√2 twice = 5)
        // Total should be close to original (may differ slightly due to average term)
        assert!(
            wavelet_energy > 0.0,
            "Wavelet energy should be positive for non-constant signal"
        );

        // Verify coarse coefficient magnitude matches paper's formula
        // Paper: d_{1,1} = (y3+y4 - y1-y2) / 2 = (3+4-1-2)/2 = 2 for signal [1,2,3,4]
        // Our orthonormal: same magnitude through iterative /√2
        let coarse_coeff = coefficients[0][0].abs();
        let expected_coarse = 2.0;
        assert!(
            (coarse_coeff - expected_coarse).abs() < 0.01,
            "Coarse coefficient {} should match paper's expected value {}",
            coarse_coeff,
            expected_coarse
        );
    }

    /// Validates energy distribution for malicious vs clean patterns per paper findings.
    /// Paper (Section 2.3.1): Malware concentrates energy at coarse levels (j=1,2,3),
    /// clean files concentrate energy at fine levels (j=4,5).
    #[test]
    fn test_energy_distribution_matches_paper_findings() {
        // Clean pattern: small local variations (fine energy dominates)
        let clean: Vec<f64> = vec![5.0, 5.1, 4.9, 5.2, 5.0, 4.8, 5.1, 5.0];
        let clean_coeffs = haar_wavelet_transform(&clean);
        let clean_energy = compute_wavelet_energy_spectrum(&clean_coeffs);
        let clean_total: f64 = clean_energy.iter().sum();
        let clean_coarse: f64 = clean_energy[..clean_energy.len() / 2].iter().sum();
        let clean_coarse_ratio = clean_coarse / clean_total;

        // Malicious pattern: large shifts between segments (coarse energy dominates)
        let malicious: Vec<f64> = vec![2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0];
        let mal_coeffs = haar_wavelet_transform(&malicious);
        let mal_energy = compute_wavelet_energy_spectrum(&mal_coeffs);
        let mal_total: f64 = mal_energy.iter().sum();
        let mal_coarse: f64 = mal_energy[..mal_energy.len() / 2].iter().sum();
        let mal_coarse_ratio = mal_coarse / mal_total;

        // Paper finding: malicious files have higher coarse energy ratio
        assert!(
            mal_coarse_ratio > clean_coarse_ratio,
            "Malicious coarse ratio {} should be > clean coarse ratio {}",
            mal_coarse_ratio,
            clean_coarse_ratio
        );

        // Malicious pattern should have very high coarse ratio (nearly all energy at coarse)
        assert!(
            mal_coarse_ratio > 0.9,
            "Malicious pattern should have >90% coarse energy, got {}",
            mal_coarse_ratio
        );
    }
}
